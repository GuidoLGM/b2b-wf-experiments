{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PROJECT_ID      = \"\"\n",
    "PROJECT_REGION  = \"\"\n",
    "\n",
    "GCS_BUCKET_NAME = \"\"\n",
    "\n",
    "VERTEX_DATASET_NAME    = \"\"\n",
    "VERTEX_MODEL_NAME      = \"\"\n",
    "VERTEX_PREDICTION_NAME = \"\"\n",
    "\n",
    "BQ_DATASET_NAME  = \"\"\n",
    "BQ_TRAIN_TABLE   = \"\"\n",
    "BQ_PREDICT_TABLE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"wb-ai-acltr-tbs-3-pr-a62583\"\n",
    "GCS_BUCKET_NAME = \"bkt_b2b_wf_prediction\"\n",
    "PROJECT_REGION = \"northamerica-northeast1\"\n",
    "\n",
    "VERTEX_DATASET_NAME = \"b2b_wf_prediction_panorama\"\n",
    "VERTEX_MODEL_NAME = \"b2b_wf_prediction_panorama\"\n",
    "VERTEX_PREDICTION_NAME = \"b2b_wf_prediction_batch\"\n",
    "\n",
    "BQ_DATASET_NAME = \"b2b_wf_prediction\"\n",
    "BQ_TRAIN_TABLE = \"vw_wf_experiment_historical\"\n",
    "BQ_PREDICT_TABLE = \"bq_wf_temp_predictions\"\n",
    "BQ_FORECAST_TABLE= \"bq_wf_forecast\"\n",
    "\n",
    "TRAIN_TEST_DATA_SPLIT = \"DATE('2024-07-01')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/workspaces/b2b-wf-experiments/src')\n",
    "\n",
    "from components.data_evaluation_preprocessor import DataEvaluationPreprocessor\n",
    "from components.data_evaluator import Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "from google.cloud import bigquery\n",
    "from dataclasses import dataclass\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "TRAINING_DATASET_BQ_PATH   = f\"bq://{PROJECT_ID}.{BQ_DATASET_NAME}.{BQ_TRAIN_TABLE}\"\n",
    "PREDICTION_DATASET_BQ_PATH = f\"bq://{PROJECT_ID}.{BQ_DATASET_NAME}.{BQ_PREDICT_TABLE}\"\n",
    "PREDICTION_OUTPUT_PREFIX   = f\"bq://{PROJECT_ID}.{BQ_DATASET_NAME}\"\n",
    "BUCKET_URI = f\"gs://{PROJECT_ID}_{GCS_BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID, \n",
    "    staging_bucket=BUCKET_URI,\n",
    "    location=PROJECT_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(\n",
    "    project=PROJECT_ID, \n",
    "    location=PROJECT_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Experiment:\n",
    "    name: str\n",
    "    model: str\n",
    "    experiment_columns: list[str]\n",
    "    objective: str\n",
    "    forecast_horizon: int\n",
    "    context_window: int\n",
    "    data_granularity_unit: str\n",
    "    holiday_regions: list[str]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_forecast_experiment = Experiment(\n",
    "    name=\"daily_forecast\",\n",
    "    model=\"AutoML\",\n",
    "    experiment_columns=[\n",
    "        \"District\",\n",
    "        \"Region_Type\",\n",
    "        \"Product\",\n",
    "        \"Product_Grp\",\n",
    "        \"Technology\",\n",
    "        \"Work_Order_Action\",\n",
    "        \"Work_Order_Action_Grp\",\n",
    "        \"Work_Force\"],\n",
    "    objective=\"minimize-rmse\",\n",
    "    forecast_horizon=184,\n",
    "    context_window=368,\n",
    "    data_granularity_unit='day',\n",
    "    holiday_regions=[\"CA\"]\n",
    ")\n",
    "\n",
    "daily_forecast_minimal_features_experiment = Experiment(\n",
    "    name=\"minimal_features_daily_forecast\",\n",
    "    model=\"AutoML\",\n",
    "    experiment_columns=[\n",
    "        \"District\",\n",
    "        \"Region_Type\",\n",
    "        \"Product_Grp\",\n",
    "        \"Work_Order_Action_Grp\"],\n",
    "    objective=\"minimize-rmse\",\n",
    "    forecast_horizon=184,\n",
    "    context_window=368,\n",
    "    data_granularity_unit='day',\n",
    "    holiday_regions=[\"CA\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_experiment = daily_forecast_minimal_features_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train data view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_series_identifier(columns):\n",
    "    coalesce_parts = [f\"COALESCE({column}, 'None')\" for column in columns]\n",
    "    separator = \"' '\"\n",
    "    return f\"CONCAT({f', {separator}, '.join(coalesce_parts)}) as Series_Identifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column                   = \"Appointment_Day\"\n",
    "time_series_identifier_column = \"Series_Identifier\"\n",
    "target_column                 = \"SWT\"\n",
    "\n",
    "FORECAST_TIMESTAMP = datetime.datetime.now()\n",
    "ATTRIBUTE_COLUMNS = running_experiment.experiment_columns\n",
    "ATTRIBUTE_STRING = ','.join(ATTRIBUTE_COLUMNS)\n",
    "\n",
    "COLUMN_SPECS = {\n",
    "    time_column:             \"timestamp\",\n",
    "    target_column:           \"numeric\"\n",
    "}\n",
    "\n",
    "for category in ATTRIBUTE_COLUMNS:\n",
    "    COLUMN_SPECS[category] = \"categorical\"\n",
    "\n",
    "\n",
    "VERTEX_MODEL_NAME += f\"_{running_experiment.name}\"\n",
    "VERTEX_DATASET_NAME += f\"_{running_experiment.name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data_cte = f\"\"\"\n",
    "WITH historical_table AS (\n",
    "  SELECT \n",
    "    {time_column},\n",
    "    {ATTRIBUTE_STRING},\n",
    "    SUM({target_column}) AS {target_column}\n",
    "  FROM `{BQ_DATASET_NAME}.vw_wf_historical`\n",
    "  WHERE Appointment_Day < {TRAIN_TEST_DATA_SPLIT}\n",
    "  GROUP BY {time_column},{ATTRIBUTE_STRING}\n",
    ")\"\"\"\n",
    "\n",
    "\n",
    "experiment_train_data_query = f\"\"\"\n",
    "CREATE OR REPLACE VIEW `{BQ_DATASET_NAME}.{BQ_TRAIN_TABLE}` AS \n",
    "{experiment_data_cte}\n",
    "SELECT \n",
    "  {create_series_identifier(ATTRIBUTE_COLUMNS)},\n",
    "  {time_column},\n",
    "  {ATTRIBUTE_STRING},\n",
    "  {target_column}\n",
    "FROM historical_table\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7fffac46a0e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_and_wait(experiment_train_data_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... creating new dataset ... \n",
      "Creating TimeSeriesDataset\n",
      "Create TimeSeriesDataset backing LRO: projects/7796273458/locations/northamerica-northeast1/datasets/1705650397936353280/operations/2547550299615133696\n",
      "TimeSeriesDataset created. Resource name: projects/7796273458/locations/northamerica-northeast1/datasets/1705650397936353280\n",
      "To use this TimeSeriesDataset in another session:\n",
      "ds = aiplatform.TimeSeriesDataset('projects/7796273458/locations/northamerica-northeast1/datasets/1705650397936353280')\n"
     ]
    }
   ],
   "source": [
    "dataset_list = aiplatform.TimeSeriesDataset.list(\n",
    "    filter=f\"display_name={VERTEX_DATASET_NAME}\"\n",
    ")\n",
    "\n",
    "if len(dataset_list) == 0:\n",
    "    print(\"... creating new dataset ... \")\n",
    "    dataset = aiplatform.TimeSeriesDataset.create(\n",
    "        display_name=VERTEX_DATASET_NAME,\n",
    "        bq_source=[TRAINING_DATASET_BQ_PATH],\n",
    "    )\n",
    "else:\n",
    "    print(\"... using existent dataset ... \")\n",
    "    dataset = dataset_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... training a new model ... \n"
     ]
    }
   ],
   "source": [
    "model_list = aiplatform.Model.list(\n",
    "    filter=f\"display_name={VERTEX_MODEL_NAME}\"\n",
    ")\n",
    "\n",
    "if len(model_list) == 0:\n",
    "    print(\"... training a new model ... \")\n",
    "    parent_model = None\n",
    "else:\n",
    "    print(\"... using existent model ... \")\n",
    "    model = model_list[0]\n",
    "    print(model)\n",
    "    parent_model = model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job = aiplatform.AutoMLForecastingTrainingJob(\n",
    "    display_name=VERTEX_MODEL_NAME,\n",
    "    optimization_objective=running_experiment.objective,\n",
    "    column_specs=COLUMN_SPECS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dataset split provided. The service will use a default split.\n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/northamerica-northeast1/training/1048846681723895808?project=7796273458\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/1048846681723895808 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "model = training_job.run(\n",
    "    dataset=dataset,\n",
    "    target_column=target_column,\n",
    "    time_column=time_column,\n",
    "    time_series_identifier_column=time_series_identifier_column,\n",
    "    available_at_forecast_columns=[time_column],\n",
    "    unavailable_at_forecast_columns=[target_column],\n",
    "    time_series_attribute_columns=ATTRIBUTE_COLUMNS,\n",
    "    forecast_horizon=running_experiment.forecast_horizon,\n",
    "    context_window=running_experiment.context_window,\n",
    "    data_granularity_unit=running_experiment.data_granularity_unit,\n",
    "    data_granularity_count=1,\n",
    "    weight_column=None,\n",
    "    budget_milli_node_hours=1000,\n",
    "    parent_model = parent_model,\n",
    "    model_display_name=VERTEX_MODEL_NAME,\n",
    "    is_default_version = True,\n",
    "    model_version_description = f\"{running_experiment.name} model generated on {datetime.date.today().isoformat()}\",\n",
    "    predefined_split_column_name=None,\n",
    "    holiday_regions=running_experiment.holiday_regions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = f\"\"\"SELECT\n",
    "    (\n",
    "      DATE(DATE_TRUNC({TRAIN_TEST_DATA_SPLIT}, DAY)) + INTERVAL i DAY\n",
    "    ) AS {time_column}\n",
    "  FROM\n",
    "    UNNEST (GENERATE_ARRAY(0, {running_experiment.forecast_horizon-1})) AS i\"\"\"\n",
    "\n",
    "columns_dim = f\"\"\"SELECT DISTINCT\n",
    "    Series_Identifier,\n",
    "    {ATTRIBUTE_STRING}\n",
    "  FROM `{BQ_DATASET_NAME}.{BQ_TRAIN_TABLE}`\n",
    "  WHERE\n",
    "      {\" IS NOT NULL AND \".join(ATTRIBUTE_COLUMNS)} IS NOT NULL\n",
    "\"\"\"\n",
    "future_values = f\"\"\"SELECT\n",
    "    h.Series_Identifier,\n",
    "    CAST(d.{time_column} AS DATE) AS {time_column},\n",
    "    {','.join(map(lambda x : f'h.{x}', ATTRIBUTE_COLUMNS))},\n",
    "    NULL AS {target_column},\n",
    "    'predicted' AS {target_column}_Type\n",
    "  FROM columns_dim h,\n",
    "    date_range d\n",
    "  \"\"\"\n",
    "\n",
    "past_values = f\"\"\"SELECT\n",
    "    Series_Identifier,\n",
    "    {time_column},\n",
    "    {ATTRIBUTE_STRING},\n",
    "    {target_column},\n",
    "    'actual' AS {target_column}_Type\n",
    "  FROM `{BQ_DATASET_NAME}.{BQ_TRAIN_TABLE}`\n",
    "  WHERE\n",
    "    {\" IS NOT NULL AND \".join(ATTRIBUTE_COLUMNS)} IS NOT NULL\"\"\"\n",
    "\n",
    "\n",
    "predicton_table_query = f\"\"\"WITH date_range AS (\n",
    "  {date_range}\n",
    "), columns_dim AS (\n",
    "  {columns_dim}\n",
    "),future_values AS (\n",
    "  {future_values}\n",
    "), past_values AS (\n",
    "  {past_values}\n",
    ")\n",
    "SELECT\n",
    "  Series_Identifier,\n",
    "  {time_column},\n",
    "  {ATTRIBUTE_STRING},\n",
    "  {target_column},\n",
    "  {target_column}_Type\n",
    "FROM future_values\n",
    "UNION ALL\n",
    "SELECT\n",
    "  Series_Identifier,\n",
    "  {time_column},\n",
    "  {ATTRIBUTE_STRING},\n",
    "  {target_column},\n",
    "  {target_column}_Type\n",
    "FROM past_values\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7fffa7f83820>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_and_wait(f\"\"\"CREATE OR REPLACE TABLE `{BQ_DATASET_NAME}.{BQ_PREDICT_TABLE}` AS {predicton_table_query}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/northamerica-northeast1/batch-predictions/4091028230012665856?project=7796273458\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/4091028230012665856\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job = model.batch_predict(\n",
    "    job_display_name=VERTEX_PREDICTION_NAME,\n",
    "    bigquery_source=PREDICTION_DATASET_BQ_PATH,\n",
    "    instances_format=\"bigquery\",\n",
    "    bigquery_destination_prefix=PREDICTION_OUTPUT_PREFIX,\n",
    "    predictions_format=\"bigquery\",\n",
    "    generate_explanation=True,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_table  = batch_prediction_job.output_info.bigquery_output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = f\"\"\"\n",
    "SELECT\n",
    "  CAST('{FORECAST_TIMESTAMP}' AS TIMESTAMP) AS Forecast_Date,\n",
    "  CAST(Appointment_Day AS DATE) AS Appointment_Day,\n",
    "  Series_Identifier,\n",
    "  {ATTRIBUTE_STRING},\n",
    "  predicted_SWT.value AS SWT\n",
    "FROM\n",
    "  `{BQ_DATASET_NAME}.{batch_table}`\n",
    "WHERE\n",
    "  SWT_Type = 'predicted'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "perisist_predictions_query = f\"\"\"\n",
    "INSERT INTO `{BQ_DATASET_NAME}.{BQ_FORECAST_TABLE}`\n",
    "(\n",
    "  Model,\n",
    "  Forecast_Date,\n",
    "  Series_Identifier,\n",
    "  Appointment_Day,\n",
    "  {ATTRIBUTE_STRING},\n",
    "  SWT\n",
    ")\n",
    "WITH prediction_data AS (\n",
    "  {prediction_data}\n",
    ")\n",
    "SELECT DISTINCT\n",
    "  '{running_experiment.model}' AS Model,\n",
    "  Forecast_Date,\n",
    "  Series_Identifier,\n",
    "  Appointment_Day,\n",
    "  {ATTRIBUTE_STRING},\n",
    "  SWT\n",
    "FROM prediction_data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "404 POST https://bigquery.googleapis.com/bigquery/v2/projects/wb-ai-acltr-tbs-3-pr-a62583/queries?prettyPrint=false: Not found: Table wb-ai-acltr-tbs-3-pr-a62583:b2b_wf_prediction.predictions_2025_02_12T02_21_46_830Z_277 was not found in location northamerica-northeast1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_and_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperisist_predictions_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m client\u001b[38;5;241m.\u001b[39mquery_and_wait(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROP TABLE `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBQ_DATASET_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_table\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:3601\u001b[0m, in \u001b[0;36mClient.query_and_wait\u001b[0;34m(self, query, job_config, location, project, api_timeout, wait_timeout, retry, job_retry, page_size, max_results)\u001b[0m\n\u001b[1;32m   3595\u001b[0m     _verify_job_config_type(job_config, QueryJobConfig)\n\u001b[1;32m   3597\u001b[0m job_config \u001b[38;5;241m=\u001b[39m _job_helpers\u001b[38;5;241m.\u001b[39mjob_config_with_defaults(\n\u001b[1;32m   3598\u001b[0m     job_config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_query_job_config\n\u001b[1;32m   3599\u001b[0m )\n\u001b[0;32m-> 3601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_job_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_and_wait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3602\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3606\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_retry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_retry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3613\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_job_helpers.py:509\u001b[0m, in \u001b[0;36mquery_and_wait\u001b[0;34m(client, query, job_config, location, project, api_timeout, wait_timeout, retry, job_retry, page_size, max_results)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39mRowIterator(\n\u001b[1;32m    493\u001b[0m         client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[1;32m    494\u001b[0m         api_request\u001b[38;5;241m=\u001b[39mfunctools\u001b[38;5;241m.\u001b[39mpartial(client\u001b[38;5;241m.\u001b[39m_call_api, retry, timeout\u001b[38;5;241m=\u001b[39mapi_timeout),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    505\u001b[0m         num_dml_affected_rows\u001b[38;5;241m=\u001b[39mquery_results\u001b[38;5;241m.\u001b[39mnum_dml_affected_rows,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_retry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjob_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo_query\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m do_query()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/_job_helpers.py:450\u001b[0m, in \u001b[0;36mquery_and_wait.<locals>.do_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# For easier testing, handle the retries ourselves.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 450\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# We're calling the retry decorator ourselves.\u001b[39;49;00m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.query\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_call_api(\n\u001b[1;32m    461\u001b[0m         retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    462\u001b[0m         span_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigQuery.query\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mapi_timeout,\n\u001b[1;32m    468\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/bigquery/client.py:833\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[1;32m    831\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[1;32m    832\u001b[0m     ):\n\u001b[0;32m--> 833\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mNotFound\u001b[0m: 404 POST https://bigquery.googleapis.com/bigquery/v2/projects/wb-ai-acltr-tbs-3-pr-a62583/queries?prettyPrint=false: Not found: Table wb-ai-acltr-tbs-3-pr-a62583:b2b_wf_prediction.predictions_2025_02_12T02_21_46_830Z_277 was not found in location northamerica-northeast1"
     ]
    }
   ],
   "source": [
    "client.query_and_wait(perisist_predictions_query)\n",
    "client.query_and_wait(f\"DROP TABLE `{BQ_DATASET_NAME}.{batch_table}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_query = f\"\"\"\n",
    "SELECT\n",
    "  DATE_TRUNC(Appointment_Day, MONTH) AS Appointment_Day,\n",
    "  Product_Grp,\n",
    "  Work_Order_Action_Grp,\n",
    "  District,\n",
    "  Region_Type,\n",
    "  SUM({target_column}) as SWT\n",
    "FROM `{BQ_DATASET_NAME}.{BQ_FORECAST_TABLE}`\n",
    "WHERE \n",
    "  Model = '{running_experiment.model}'\n",
    "  AND Forecast_Date = CAST('{FORECAST_TIMESTAMP}' AS TIMESTAMP)\n",
    "GROUP BY\n",
    "  DATE_TRUNC({time_column}, MONTH),\n",
    "  Product_Grp,\n",
    "  Work_Order_Action_Grp,\n",
    "  District,\n",
    "  Region_Type\n",
    "ORDER BY\n",
    "  {time_column},\n",
    "  Product_Grp,\n",
    "  Work_Order_Action_Grp,\n",
    "  District,\n",
    "  Region_Type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = client.query_and_wait(forecast_query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appointment_Day</th>\n",
       "      <th>Product_Grp</th>\n",
       "      <th>Work_Order_Action_Grp</th>\n",
       "      <th>District</th>\n",
       "      <th>Region_Type</th>\n",
       "      <th>SWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Abitibi</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>2271.060026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Amqui</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>1926.847691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Baie-Comeau</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>2985.671451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Basse Côte-Nord</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>1111.542418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Bonaventure</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>1831.934429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Appointment_Day Product_Grp Work_Order_Action_Grp             District  \\\n",
       "0      2024-07-01     Managed               Install          AFF Abitibi   \n",
       "1      2024-07-01     Managed               Install            AFF Amqui   \n",
       "2      2024-07-01     Managed               Install      AFF Baie-Comeau   \n",
       "3      2024-07-01     Managed               Install  AFF Basse Côte-Nord   \n",
       "4      2024-07-01     Managed               Install      AFF Bonaventure   \n",
       "\n",
       "  Region_Type          SWT  \n",
       "0      Tier 2  2271.060026  \n",
       "1      Tier 3  1926.847691  \n",
       "2      Tier 3  2985.671451  \n",
       "3      Tier 3  1111.542418  \n",
       "4      Tier 3  1831.934429  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_query = f\"\"\"\n",
    "WITH historical_table AS (\n",
    "  SELECT \n",
    "    DATE_TRUNC({time_column}, MONTH) AS Appointment_Day,\n",
    "    Product_Grp,\n",
    "    Work_Order_Action_Grp,\n",
    "    District,\n",
    "    Region_Type,\n",
    "    SUM({target_column}) AS SWT\n",
    "  FROM `{BQ_DATASET_NAME}.vw_wf_historical`\n",
    "  WHERE {time_column} BETWEEN {TRAIN_TEST_DATA_SPLIT} AND DATE('2025-01-01')\n",
    "  GROUP BY \n",
    "    DATE_TRUNC({time_column}, MONTH),\n",
    "    Product_Grp,\n",
    "    Work_Order_Action_Grp,\n",
    "    District,\n",
    "    Region_Type\n",
    ")\n",
    "SELECT\n",
    "  Appointment_Day,\n",
    "  Product_Grp,\n",
    "  Work_Order_Action_Grp,\n",
    "  District,\n",
    "  Region_Type,\n",
    "  SWT\n",
    "FROM historical_table\n",
    "ORDER BY\n",
    "  Appointment_Day,\n",
    "  Product_Grp,\n",
    "  Work_Order_Action_Grp,\n",
    "  District,\n",
    "  Region_Type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df = client.query_and_wait(historical_query).to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appointment_Day</th>\n",
       "      <th>Product_Grp</th>\n",
       "      <th>Work_Order_Action_Grp</th>\n",
       "      <th>District</th>\n",
       "      <th>Region_Type</th>\n",
       "      <th>SWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Abitibi</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>12.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Amqui</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>7.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Baie-Comeau</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>5.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Basse Côte-Nord</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>35.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Bonaventure</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>4.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Appointment_Day Product_Grp Work_Order_Action_Grp             District  \\\n",
       "0      2024-07-01     Managed               Install          AFF Abitibi   \n",
       "1      2024-07-01     Managed               Install            AFF Amqui   \n",
       "2      2024-07-01     Managed               Install      AFF Baie-Comeau   \n",
       "3      2024-07-01     Managed               Install  AFF Basse Côte-Nord   \n",
       "4      2024-07-01     Managed               Install      AFF Bonaventure   \n",
       "\n",
       "  Region_Type           SWT  \n",
       "0      Tier 2  12.000000000  \n",
       "1      Tier 3   7.000000000  \n",
       "2      Tier 3   5.000000000  \n",
       "3      Tier 3  35.000000000  \n",
       "4      Tier 3   4.000000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = DataEvaluationPreprocessor(historical_df)\n",
    "forecast_data = DataEvaluationPreprocessor(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = Evaluation(historical_data, forecast_data)\n",
    "\n",
    "rmse = {\n",
    "    'overall': evaluation.calculate_metric('rmse'),\n",
    "    'Tier 1': evaluation.calculate_metric('rmse', filters={'Region_Type': 'Tier 1'}),\n",
    "    'Tier 2': evaluation.calculate_metric('rmse', filters={'Region_Type': 'Tier 2'}),\n",
    "    'Tier 3': evaluation.calculate_metric('rmse', filters={'Region_Type': 'Tier 3'})\n",
    "}\n",
    "\n",
    "wape = {\n",
    "    'overall': evaluation.calculate_metric('wape'),\n",
    "    'Tier 1': evaluation.calculate_metric('wape', filters={'Region_Type': 'Tier 1'}),\n",
    "    'Tier 2': evaluation.calculate_metric('wape', filters={'Region_Type': 'Tier 2'}),\n",
    "    'Tier 3': evaluation.calculate_metric('wape', filters={'Region_Type': 'Tier 3'})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_insert_query = f\"\"\"\n",
    "INSERT INTO `{BQ_DATASET_NAME}.bq_wf_evaluation`\n",
    "  (Model, Forecast_Date, Experiment_Config, WAPE, RMSE)\n",
    "VALUES (\n",
    "  '{running_experiment.model}',               \n",
    "  '{FORECAST_TIMESTAMP}',\n",
    "  STRUCT(\n",
    "    '{running_experiment.name}' AS Name,\n",
    "    '{running_experiment.objective}' AS Objective,\n",
    "    {running_experiment.forecast_horizon} AS Forecast_Horizon,\n",
    "    {running_experiment.context_window} AS Context_Window,\n",
    "    '{running_experiment.data_granularity_unit}' AS Data_Granularity_Unit,\n",
    "    {json.dumps(running_experiment.holiday_regions)} AS Holiday_Regions,\n",
    "    {json.dumps(running_experiment.experiment_columns)} AS Experiment_Columns\n",
    "  ),\n",
    "  STRUCT(\n",
    "    {wape['overall']} AS Overall,\n",
    "    {wape['Tier 1']} AS Tier_1,\n",
    "    {wape['Tier 2']} AS Tier_2,\n",
    "    {wape['Tier 3']} AS Tier_3\n",
    "  ),\n",
    "  STRUCT(\n",
    "    {rmse['overall']} AS Overall,\n",
    "    {rmse['Tier 1']} AS Tier_1,\n",
    "    {rmse['Tier 2']} AS Tier_2,\n",
    "    {rmse['Tier 3']} AS Tier_3\n",
    "  )\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7fffa7c88a60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_and_wait(evaluation_insert_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
