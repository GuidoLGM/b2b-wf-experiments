{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "PROJECT_ID      = \"\"\n",
    "PROJECT_REGION  = \"\"\n",
    "\n",
    "GCS_BUCKET_NAME = \"\"\n",
    "\n",
    "VERTEX_DATASET_NAME    = \"\"\n",
    "VERTEX_MODEL_NAME      = \"\"\n",
    "VERTEX_PREDICTION_NAME = \"\"\n",
    "\n",
    "BQ_DATASET_NAME  = \"\"\n",
    "BQ_TRAIN_TABLE   = \"\"\n",
    "BQ_PREDICT_TABLE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"wb-ai-acltr-tbs-3-pr-a62583\"\n",
    "GCS_BUCKET_NAME = \"bkt_b2b_wf_prediction\"\n",
    "PROJECT_REGION = \"northamerica-northeast1\"\n",
    "\n",
    "VERTEX_DATASET_NAME = \"b2b_wf_prediction_panorama\"\n",
    "VERTEX_MODEL_NAME = \"b2b_wf_prediction_panorama\"\n",
    "VERTEX_PREDICTION_NAME = \"b2b_wf_prediction_batch\"\n",
    "\n",
    "BQ_DATASET_NAME = \"b2b_wf_prediction\"\n",
    "BQ_TRAIN_TABLE = \"vw_wf_experiment_historical\"\n",
    "BQ_PREDICT_TABLE = \"bq_wf_temp_predictions\"\n",
    "BQ_FORECAST_TABLE= \"bq_wf_forecast\"\n",
    "\n",
    "TRAIN_TEST_DATA_SPLIT = \"DATE('2024-07-01')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/workspaces/b2b-wf-experiments/src')\n",
    "\n",
    "from components.data_evaluation_preprocessor import DataEvaluationPreprocessor\n",
    "from components.data_evaluator import Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "from google.cloud import bigquery\n",
    "from dataclasses import dataclass\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "TRAINING_DATASET_BQ_PATH   = f\"bq://{PROJECT_ID}.{BQ_DATASET_NAME}.{BQ_TRAIN_TABLE}\"\n",
    "PREDICTION_DATASET_BQ_PATH = f\"bq://{PROJECT_ID}.{BQ_DATASET_NAME}.{BQ_PREDICT_TABLE}\"\n",
    "PREDICTION_OUTPUT_PREFIX   = f\"bq://{PROJECT_ID}.{BQ_DATASET_NAME}\"\n",
    "BUCKET_URI = f\"gs://{PROJECT_ID}_{GCS_BUCKET_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID, \n",
    "    staging_bucket=BUCKET_URI,\n",
    "    location=PROJECT_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/google/auth/_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(\n",
    "    project=PROJECT_ID, \n",
    "    location=PROJECT_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Experiment:\n",
    "    name: str\n",
    "    model: str\n",
    "    experiment_columns: list[str]\n",
    "    objective: str\n",
    "    forecast_horizon: int\n",
    "    context_window: int\n",
    "    data_granularity_unit: str\n",
    "    holiday_regions: list[str]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_forecast_experiment = Experiment(\n",
    "    name=\"daily_forecast\",\n",
    "    model=\"AutoML\",\n",
    "    experiment_columns=[\n",
    "        \"District\",\n",
    "        \"Region_Type\",\n",
    "        \"Product\",\n",
    "        \"Product_Grp\",\n",
    "        \"Technology\",\n",
    "        \"Work_Order_Action\",\n",
    "        \"Work_Order_Action_Grp\",\n",
    "        \"Work_Force\"],\n",
    "    objective=\"minimize-rmse\",\n",
    "    forecast_horizon=184,\n",
    "    context_window=368,\n",
    "    data_granularity_unit='day',\n",
    "    holiday_regions=[\"CA\"]\n",
    ")\n",
    "\n",
    "daily_forecast_minimal_features_experiment = Experiment(\n",
    "    name=\"minimal_features_daily_forecast\",\n",
    "    model=\"AutoML\",\n",
    "    experiment_columns=[\n",
    "        \"District\",\n",
    "        \"Region_Type\",\n",
    "        \"Product_Grp\",\n",
    "        \"Work_Order_Action_Grp\"],\n",
    "    objective=\"minimize-rmse\",\n",
    "    forecast_horizon=184,\n",
    "    context_window=368,\n",
    "    data_granularity_unit='day',\n",
    "    holiday_regions=[\"CA\"]\n",
    ")\n",
    "\n",
    "weekly_forecast_minimal_features_experiment = Experiment(\n",
    "    name=\"minimal_features_daily_forecast\",\n",
    "    model=\"AutoML\",\n",
    "    experiment_columns=[\n",
    "        \"District\",\n",
    "        \"Region_Type\",\n",
    "        \"Product_Grp\",\n",
    "        \"Work_Order_Action_Grp\"],\n",
    "    objective=\"minimize-rmse\",\n",
    "    forecast_horizon=20,\n",
    "    context_window=40,\n",
    "    data_granularity_unit='week',\n",
    "    holiday_regions=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_experiment = weekly_forecast_minimal_features_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train data view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_series_identifier(columns):\n",
    "    coalesce_parts = [f\"COALESCE({column}, 'None')\" for column in columns]\n",
    "    separator = \"' '\"\n",
    "    return f\"CONCAT({f', {separator}, '.join(coalesce_parts)}) as Series_Identifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column                   = \"Appointment_Day\"\n",
    "time_series_identifier_column = \"Series_Identifier\"\n",
    "target_column                 = \"SWT\"\n",
    "\n",
    "FORECAST_TIMESTAMP = datetime.datetime.now()\n",
    "ATTRIBUTE_COLUMNS = running_experiment.experiment_columns\n",
    "ATTRIBUTE_STRING = ','.join(ATTRIBUTE_COLUMNS)\n",
    "\n",
    "COLUMN_SPECS = {\n",
    "    time_column:             \"timestamp\",\n",
    "    target_column:           \"numeric\"\n",
    "}\n",
    "\n",
    "for category in ATTRIBUTE_COLUMNS:\n",
    "    COLUMN_SPECS[category] = \"categorical\"\n",
    "\n",
    "\n",
    "VERTEX_MODEL_NAME += f\"_{running_experiment.name}\"\n",
    "VERTEX_DATASET_NAME += f\"_{running_experiment.name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_data_cte = f\"\"\"\n",
    "WITH historical_table AS (\n",
    "  SELECT \n",
    "    {time_column},\n",
    "    {ATTRIBUTE_STRING},\n",
    "    SUM({target_column}) AS {target_column}\n",
    "  FROM `{BQ_DATASET_NAME}.vw_wf_historical`\n",
    "  WHERE Appointment_Day < {TRAIN_TEST_DATA_SPLIT}\n",
    "  GROUP BY {time_column},{ATTRIBUTE_STRING}\n",
    ")\"\"\"\n",
    "\n",
    "\n",
    "experiment_train_data_query = f\"\"\"\n",
    "CREATE OR REPLACE VIEW `{BQ_DATASET_NAME}.{BQ_TRAIN_TABLE}` AS \n",
    "{experiment_data_cte}\n",
    "SELECT \n",
    "  {create_series_identifier(ATTRIBUTE_COLUMNS)},\n",
    "  {time_column},\n",
    "  {ATTRIBUTE_STRING},\n",
    "  {target_column}\n",
    "FROM historical_table\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7fffac46efe0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_and_wait(experiment_train_data_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... using existent dataset ... \n"
     ]
    }
   ],
   "source": [
    "dataset_list = aiplatform.TimeSeriesDataset.list(\n",
    "    filter=f\"display_name={VERTEX_DATASET_NAME}\"\n",
    ")\n",
    "\n",
    "if len(dataset_list) == 0:\n",
    "    print(\"... creating new dataset ... \")\n",
    "    dataset = aiplatform.TimeSeriesDataset.create(\n",
    "        display_name=VERTEX_DATASET_NAME,\n",
    "        bq_source=[TRAINING_DATASET_BQ_PATH],\n",
    "    )\n",
    "else:\n",
    "    print(\"... using existent dataset ... \")\n",
    "    dataset = dataset_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... using existent model ... \n",
      "<google.cloud.aiplatform.models.Model object at 0x7fffa7f81030> \n",
      "resource name: projects/7796273458/locations/northamerica-northeast1/models/4937075489551417344\n"
     ]
    }
   ],
   "source": [
    "model_list = aiplatform.Model.list(\n",
    "    filter=f\"display_name={VERTEX_MODEL_NAME}\"\n",
    ")\n",
    "\n",
    "if len(model_list) == 0:\n",
    "    print(\"... training a new model ... \")\n",
    "    parent_model = None\n",
    "else:\n",
    "    print(\"... using existent model ... \")\n",
    "    model = model_list[0]\n",
    "    print(model)\n",
    "    parent_model = model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job = aiplatform.AutoMLForecastingTrainingJob(\n",
    "    display_name=VERTEX_MODEL_NAME,\n",
    "    optimization_objective=running_experiment.objective,\n",
    "    column_specs=COLUMN_SPECS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dataset split provided. The service will use a default split.\n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/northamerica-northeast1/training/5800847976041545728?project=7796273458\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLForecastingTrainingJob projects/7796273458/locations/northamerica-northeast1/trainingPipelines/5800847976041545728 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "Timeout of 120.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:198.161.14.25:8080: tcp handshaker shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1181\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1175\u001b[0m (\n\u001b[1;32m   1176\u001b[0m     state,\n\u001b[1;32m   1177\u001b[0m     call,\n\u001b[1;32m   1178\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1179\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1180\u001b[0m )\n\u001b[0;32m-> 1181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:198.161.14.25:8080: tcp handshaker shutdown\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-02-13T18:27:34.676064128+00:00\", grpc_status:14, grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv4:198.161.14.25:8080: tcp handshaker shutdown\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:198.161.14.25:8080: tcp handshaker shutdown",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_series_identifier_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_series_identifier_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavailable_at_forecast_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtime_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43munavailable_at_forecast_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_series_attribute_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mATTRIBUTE_COLUMNS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrunning_experiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforecast_horizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrunning_experiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_granularity_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrunning_experiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_granularity_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_granularity_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbudget_milli_node_hours\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparent_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_display_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVERTEX_MODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_default_version\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_version_description\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrunning_experiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m model generated on \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoday\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misoformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredefined_split_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mholiday_regions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrunning_experiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mholiday_regions\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:2204\u001b[0m, in \u001b[0;36m_ForecastingTrainingJob.run\u001b[0;34m(self, dataset, target_column, time_column, time_series_identifier_column, unavailable_at_forecast_columns, available_at_forecast_columns, forecast_horizon, data_granularity_unit, data_granularity_count, training_fraction_split, validation_fraction_split, test_fraction_split, predefined_split_column_name, timestamp_split_column_name, weight_column, time_series_attribute_columns, context_window, export_evaluated_data_items, export_evaluated_data_items_bigquery_destination_uri, export_evaluated_data_items_override_destination, quantiles, validation_options, budget_milli_node_hours, model_display_name, model_labels, model_id, parent_model, is_default_version, model_version_aliases, model_version_description, additional_experiments, hierarchy_group_columns, hierarchy_group_total_weight, hierarchy_temporal_total_weight, hierarchy_group_temporal_total_weight, window_column, window_stride_length, window_max_count, holiday_regions, sync, create_request_timeout, enable_probabilistic_inference)\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m additional_experiments:\n\u001b[1;32m   2202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_additional_experiments(additional_experiments)\n\u001b[0;32m-> 2204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_series_identifier_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_series_identifier_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m    \u001b[49m\u001b[43munavailable_at_forecast_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munavailable_at_forecast_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavailable_at_forecast_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mavailable_at_forecast_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecast_horizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_granularity_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_granularity_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_granularity_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_granularity_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredefined_split_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredefined_split_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_split_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_split_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_series_attribute_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_series_attribute_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbudget_milli_node_hours\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbudget_milli_node_hours\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_evaluated_data_items\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_evaluated_data_items\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_evaluated_data_items_bigquery_destination_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_evaluated_data_items_bigquery_destination_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_evaluated_data_items_override_destination\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_evaluated_data_items_override_destination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_display_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_display_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_default_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_default_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_version_aliases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_version_aliases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_version_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_version_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhierarchy_group_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhierarchy_group_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhierarchy_group_total_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhierarchy_group_total_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhierarchy_temporal_total_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhierarchy_temporal_total_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhierarchy_group_temporal_total_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhierarchy_group_temporal_total_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_stride_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_stride_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_max_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_max_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mholiday_regions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholiday_regions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_probabilistic_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_probabilistic_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:863\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    862\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    866\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:2658\u001b[0m, in \u001b[0;36m_ForecastingTrainingJob._run\u001b[0;34m(self, dataset, target_column, time_column, time_series_identifier_column, unavailable_at_forecast_columns, available_at_forecast_columns, forecast_horizon, data_granularity_unit, data_granularity_count, training_fraction_split, validation_fraction_split, test_fraction_split, predefined_split_column_name, timestamp_split_column_name, weight_column, time_series_attribute_columns, context_window, export_evaluated_data_items, export_evaluated_data_items_bigquery_destination_uri, export_evaluated_data_items_override_destination, quantiles, validation_options, budget_milli_node_hours, model_display_name, model_labels, model_id, parent_model, is_default_version, model_version_aliases, model_version_description, hierarchy_group_columns, hierarchy_group_total_weight, hierarchy_temporal_total_weight, hierarchy_group_temporal_total_weight, window_column, window_stride_length, window_max_count, holiday_regions, sync, create_request_timeout, enable_probabilistic_inference)\u001b[0m\n\u001b[1;32m   2648\u001b[0m     training_task_inputs_dict[\n\u001b[1;32m   2649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditionalExperiments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2650\u001b[0m     ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_additional_experiments\n\u001b[1;32m   2652\u001b[0m model \u001b[38;5;241m=\u001b[39m gca_model\u001b[38;5;241m.\u001b[39mModel(\n\u001b[1;32m   2653\u001b[0m     display_name\u001b[38;5;241m=\u001b[39mmodel_display_name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display_name,\n\u001b[1;32m   2654\u001b[0m     labels\u001b[38;5;241m=\u001b[39mmodel_labels \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_labels,\n\u001b[1;32m   2655\u001b[0m     encryption_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_encryption_spec,\n\u001b[1;32m   2656\u001b[0m )\n\u001b[0;32m-> 2658\u001b[0m new_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_task_definition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_training_task_definition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_task_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_task_inputs_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_fraction_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_fraction_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredefined_split_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredefined_split_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_split_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_split_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparent_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_default_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_default_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_version_aliases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_version_aliases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_version_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_version_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2674\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m export_evaluated_data_items:\n\u001b[1;32m   2677\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExported examples available at:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2679\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluated_data_items_bigquery_uri\n\u001b[1;32m   2680\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:854\u001b[0m, in \u001b[0;36m_TrainingJob._run_job\u001b[0;34m(self, training_task_definition, training_task_inputs, dataset, training_fraction_split, validation_fraction_split, test_fraction_split, training_filter_split, validation_filter_split, test_filter_split, predefined_split_column_name, timestamp_split_column_name, annotation_schema_uri, model, model_id, parent_model, is_default_version, model_version_aliases, model_version_description, gcs_destination_uri_prefix, bigquery_destination, create_request_timeout, block)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m training_pipeline\n\u001b[1;32m    852\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mView Training:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dashboard_uri())\n\u001b[0;32m--> 854\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    857\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining did not produce a Managed Model returning None. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_upload_fail_string\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:941\u001b[0m, in \u001b[0;36m_TrainingJob._get_model\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to get and instantiate the Model to Upload.\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m    RuntimeError: If Training failed.\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m--> 941\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_failed:\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Pipeline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresource_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed. No model available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    946\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:968\u001b[0m, in \u001b[0;36m_TrainingJob._block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    964\u001b[0m log_wait \u001b[38;5;241m=\u001b[39m _LOG_WAIT_TIME\n\u001b[1;32m    966\u001b[0m previous_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _PIPELINE_COMPLETE_STATES:\n\u001b[1;32m    969\u001b[0m     current_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_time \u001b[38;5;241m-\u001b[39m previous_time \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m log_wait:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/training_jobs.py:883\u001b[0m, in \u001b[0;36m_TrainingJob.state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_has_run():\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 883\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sync_gca_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:699\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._sync_gca_resource\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sync_gca_resource\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    697\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sync GAPIC service representation of client class resource.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gca_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:692\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns GAPIC service representation of client class resource.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m        Should not include project and location.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m resource_name \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mfull_resource_name(\n\u001b[1;32m    682\u001b[0m     resource_name\u001b[38;5;241m=\u001b[39mresource_name,\n\u001b[1;32m    683\u001b[0m     resource_noun\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_noun,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m     resource_id_validator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_id_validator,\n\u001b[1;32m    690\u001b[0m )\n\u001b[0;32m--> 692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getter_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_DEFAULT_RETRY\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/pipeline_service/client.py:1114\u001b[0m, in \u001b[0;36mPipelineServiceClient.get_training_pipeline\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:221\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deadline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m next_sleep \u001b[38;5;241m>\u001b[39m deadline:\n\u001b[1;32m    216\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    217\u001b[0m         error_list,\n\u001b[1;32m    218\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mTIMEOUT,\n\u001b[1;32m    219\u001b[0m         original_timeout,\n\u001b[1;32m    220\u001b[0m     )\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    222\u001b[0m _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying due to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, sleeping \u001b[39m\u001b[38;5;132;01m{:.1f}\u001b[39;00m\u001b[38;5;124ms ...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(error_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], next_sleep)\n\u001b[1;32m    224\u001b[0m )\n",
      "\u001b[0;31mRetryError\u001b[0m: Timeout of 120.0s exceeded, last exception: 503 failed to connect to all addresses; last error: UNKNOWN: ipv4:198.161.14.25:8080: tcp handshaker shutdown"
     ]
    }
   ],
   "source": [
    "model = training_job.run(\n",
    "    dataset=dataset,\n",
    "    target_column=target_column,\n",
    "    time_column=time_column,\n",
    "    time_series_identifier_column=time_series_identifier_column,\n",
    "    available_at_forecast_columns=[time_column],\n",
    "    unavailable_at_forecast_columns=[target_column],\n",
    "    time_series_attribute_columns=ATTRIBUTE_COLUMNS,\n",
    "    forecast_horizon=running_experiment.forecast_horizon,\n",
    "    context_window=running_experiment.context_window,\n",
    "    data_granularity_unit=running_experiment.data_granularity_unit,\n",
    "    data_granularity_count=1,\n",
    "    weight_column=None,\n",
    "    budget_milli_node_hours=1000,\n",
    "    parent_model = parent_model,\n",
    "    model_display_name=VERTEX_MODEL_NAME,\n",
    "    is_default_version = True,\n",
    "    model_version_description = f\"{running_experiment.name} model generated on {datetime.date.today().isoformat()}\",\n",
    "    predefined_split_column_name=None,\n",
    "    holiday_regions=running_experiment.holiday_regions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = f\"\"\"SELECT\n",
    "    (\n",
    "      DATE(DATE_TRUNC({TRAIN_TEST_DATA_SPLIT}, DAY)) + INTERVAL i DAY\n",
    "    ) AS {time_column}\n",
    "  FROM\n",
    "    UNNEST (GENERATE_ARRAY(0, {running_experiment.forecast_horizon-1})) AS i\"\"\"\n",
    "\n",
    "columns_dim = f\"\"\"SELECT DISTINCT\n",
    "    Series_Identifier,\n",
    "    {ATTRIBUTE_STRING}\n",
    "  FROM `{BQ_DATASET_NAME}.{BQ_TRAIN_TABLE}`\n",
    "  WHERE\n",
    "      {\" IS NOT NULL AND \".join(ATTRIBUTE_COLUMNS)} IS NOT NULL\n",
    "\"\"\"\n",
    "future_values = f\"\"\"SELECT\n",
    "    h.Series_Identifier,\n",
    "    CAST(d.{time_column} AS DATE) AS {time_column},\n",
    "    {','.join(map(lambda x : f'h.{x}', ATTRIBUTE_COLUMNS))},\n",
    "    NULL AS {target_column},\n",
    "    'predicted' AS {target_column}_Type\n",
    "  FROM columns_dim h,\n",
    "    date_range d\n",
    "  \"\"\"\n",
    "\n",
    "past_values = f\"\"\"SELECT\n",
    "    Series_Identifier,\n",
    "    {time_column},\n",
    "    {ATTRIBUTE_STRING},\n",
    "    {target_column},\n",
    "    'actual' AS {target_column}_Type\n",
    "  FROM `{BQ_DATASET_NAME}.{BQ_TRAIN_TABLE}`\n",
    "  WHERE\n",
    "    {\" IS NOT NULL AND \".join(ATTRIBUTE_COLUMNS)} IS NOT NULL\"\"\"\n",
    "\n",
    "\n",
    "predicton_table_query = f\"\"\"WITH date_range AS (\n",
    "  {date_range}\n",
    "), columns_dim AS (\n",
    "  {columns_dim}\n",
    "),future_values AS (\n",
    "  {future_values}\n",
    "), past_values AS (\n",
    "  {past_values}\n",
    ")\n",
    "SELECT\n",
    "  Series_Identifier,\n",
    "  {time_column},\n",
    "  {ATTRIBUTE_STRING},\n",
    "  {target_column},\n",
    "  {target_column}_Type\n",
    "FROM future_values\n",
    "UNION ALL\n",
    "SELECT\n",
    "  Series_Identifier,\n",
    "  {time_column},\n",
    "  {ATTRIBUTE_STRING},\n",
    "  {target_column},\n",
    "  {target_column}_Type\n",
    "FROM past_values\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7fff67128070>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_and_wait(f\"\"\"CREATE OR REPLACE TABLE `{BQ_DATASET_NAME}.{BQ_PREDICT_TABLE}` AS {predicton_table_query}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/northamerica-northeast1/batch-predictions/3575366072678744064?project=7796273458\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "BatchPredictionJob run completed. Resource name: projects/7796273458/locations/northamerica-northeast1/batchPredictionJobs/3575366072678744064\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job = model.batch_predict(\n",
    "    job_display_name=VERTEX_PREDICTION_NAME,\n",
    "    bigquery_source=PREDICTION_DATASET_BQ_PATH,\n",
    "    instances_format=\"bigquery\",\n",
    "    bigquery_destination_prefix=PREDICTION_OUTPUT_PREFIX,\n",
    "    predictions_format=\"bigquery\",\n",
    "    generate_explanation=True,\n",
    "    sync=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_table  = batch_prediction_job.output_info.bigquery_output_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = f\"\"\"\n",
    "SELECT\n",
    "  CAST('{FORECAST_TIMESTAMP}' AS TIMESTAMP) AS Forecast_Date,\n",
    "  CAST(Appointment_Day AS DATE) AS Appointment_Day,\n",
    "  Series_Identifier,\n",
    "  {ATTRIBUTE_STRING},\n",
    "  predicted_SWT.value AS SWT\n",
    "FROM\n",
    "  `{BQ_DATASET_NAME}.{batch_table}`\n",
    "WHERE\n",
    "  SWT_Type = 'predicted'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "perisist_predictions_query = f\"\"\"\n",
    "INSERT INTO `{BQ_DATASET_NAME}.{BQ_FORECAST_TABLE}`\n",
    "(\n",
    "  Model,\n",
    "  Forecast_Date,\n",
    "  Series_Identifier,\n",
    "  Appointment_Day,\n",
    "  {ATTRIBUTE_STRING},\n",
    "  SWT\n",
    ")\n",
    "WITH prediction_data AS (\n",
    "  {prediction_data}\n",
    ")\n",
    "SELECT DISTINCT\n",
    "  '{running_experiment.model}' AS Model,\n",
    "  Forecast_Date,\n",
    "  Series_Identifier,\n",
    "  Appointment_Day,\n",
    "  {ATTRIBUTE_STRING},\n",
    "  SWT\n",
    "FROM prediction_data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7fff67116d70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_and_wait(perisist_predictions_query)\n",
    "client.query_and_wait(f\"DROP TABLE `{BQ_DATASET_NAME}.{batch_table}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_query = f\"\"\"\n",
    "SELECT\n",
    "  DATE_TRUNC(Appointment_Day, MONTH) AS Appointment_Day,\n",
    "  Product_Grp,\n",
    "  Work_Order_Action_Grp,\n",
    "  District,\n",
    "  Region_Type,\n",
    "  SUM({target_column}) as SWT\n",
    "FROM `{BQ_DATASET_NAME}.{BQ_FORECAST_TABLE}`\n",
    "WHERE \n",
    "  Model = '{running_experiment.model}'\n",
    "  AND Forecast_Date = CAST('{FORECAST_TIMESTAMP}' AS TIMESTAMP)\n",
    "GROUP BY\n",
    "  DATE_TRUNC({time_column}, MONTH),\n",
    "  Product_Grp,\n",
    "  Work_Order_Action_Grp,\n",
    "  District,\n",
    "  Region_Type\n",
    "ORDER BY\n",
    "  {time_column},\n",
    "  Product_Grp,\n",
    "  Work_Order_Action_Grp,\n",
    "  District,\n",
    "  Region_Type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = client.query_and_wait(forecast_query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appointment_Day</th>\n",
       "      <th>Product_Grp</th>\n",
       "      <th>Work_Order_Action_Grp</th>\n",
       "      <th>District</th>\n",
       "      <th>Region_Type</th>\n",
       "      <th>SWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Abitibi</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>17.160639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Amqui</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>9.884507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Baie-Comeau</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>16.142521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Basse Côte-Nord</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>10.940392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Bonaventure</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>14.048831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Appointment_Day Product_Grp Work_Order_Action_Grp             District  \\\n",
       "0      2024-07-01     Managed               Install          AFF Abitibi   \n",
       "1      2024-07-01     Managed               Install            AFF Amqui   \n",
       "2      2024-07-01     Managed               Install      AFF Baie-Comeau   \n",
       "3      2024-07-01     Managed               Install  AFF Basse Côte-Nord   \n",
       "4      2024-07-01     Managed               Install      AFF Bonaventure   \n",
       "\n",
       "  Region_Type        SWT  \n",
       "0      Tier 2  17.160639  \n",
       "1      Tier 3   9.884507  \n",
       "2      Tier 3  16.142521  \n",
       "3      Tier 3  10.940392  \n",
       "4      Tier 3  14.048831  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_query = f\"\"\"\n",
    "WITH historical_table AS (\n",
    "  SELECT \n",
    "    DATE_TRUNC({time_column}, MONTH) AS Appointment_Day,\n",
    "    Product_Grp,\n",
    "    Work_Order_Action_Grp,\n",
    "    District,\n",
    "    Region_Type,\n",
    "    SUM({target_column}) AS SWT\n",
    "  FROM `{BQ_DATASET_NAME}.vw_wf_historical`\n",
    "  WHERE {time_column} BETWEEN {TRAIN_TEST_DATA_SPLIT} AND DATE('2025-01-01')\n",
    "  GROUP BY \n",
    "    DATE_TRUNC({time_column}, MONTH),\n",
    "    Product_Grp,\n",
    "    Work_Order_Action_Grp,\n",
    "    District,\n",
    "    Region_Type\n",
    ")\n",
    "SELECT\n",
    "  Appointment_Day,\n",
    "  Product_Grp,\n",
    "  Work_Order_Action_Grp,\n",
    "  District,\n",
    "  Region_Type,\n",
    "  SWT\n",
    "FROM historical_table\n",
    "ORDER BY\n",
    "  Appointment_Day,\n",
    "  Product_Grp,\n",
    "  Work_Order_Action_Grp,\n",
    "  District,\n",
    "  Region_Type\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df = client.query_and_wait(historical_query).to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Appointment_Day</th>\n",
       "      <th>Product_Grp</th>\n",
       "      <th>Work_Order_Action_Grp</th>\n",
       "      <th>District</th>\n",
       "      <th>Region_Type</th>\n",
       "      <th>SWT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Abitibi</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>12.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Amqui</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>7.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Baie-Comeau</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>5.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Basse Côte-Nord</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>35.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>Managed</td>\n",
       "      <td>Install</td>\n",
       "      <td>AFF Bonaventure</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>4.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Appointment_Day Product_Grp Work_Order_Action_Grp             District  \\\n",
       "0      2024-07-01     Managed               Install          AFF Abitibi   \n",
       "1      2024-07-01     Managed               Install            AFF Amqui   \n",
       "2      2024-07-01     Managed               Install      AFF Baie-Comeau   \n",
       "3      2024-07-01     Managed               Install  AFF Basse Côte-Nord   \n",
       "4      2024-07-01     Managed               Install      AFF Bonaventure   \n",
       "\n",
       "  Region_Type           SWT  \n",
       "0      Tier 2  12.000000000  \n",
       "1      Tier 3   7.000000000  \n",
       "2      Tier 3   5.000000000  \n",
       "3      Tier 3  35.000000000  \n",
       "4      Tier 3   4.000000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = DataEvaluationPreprocessor(historical_df)\n",
    "forecast_data = DataEvaluationPreprocessor(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = Evaluation(historical_data, forecast_data)\n",
    "\n",
    "rmse = {\n",
    "    'overall': evaluation.calculate_metric('rmse'),\n",
    "    'Tier 1': evaluation.calculate_metric('rmse', filters={'Region_Type': 'Tier 1'}),\n",
    "    'Tier 2': evaluation.calculate_metric('rmse', filters={'Region_Type': 'Tier 2'}),\n",
    "    'Tier 3': evaluation.calculate_metric('rmse', filters={'Region_Type': 'Tier 3'})\n",
    "}\n",
    "\n",
    "wape = {\n",
    "    'overall': evaluation.calculate_metric('wape'),\n",
    "    'Tier 1': evaluation.calculate_metric('wape', filters={'Region_Type': 'Tier 1'}),\n",
    "    'Tier 2': evaluation.calculate_metric('wape', filters={'Region_Type': 'Tier 2'}),\n",
    "    'Tier 3': evaluation.calculate_metric('wape', filters={'Region_Type': 'Tier 3'})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_insert_query = f\"\"\"\n",
    "INSERT INTO `{BQ_DATASET_NAME}.bq_wf_evaluation`\n",
    "  (Model, Forecast_Date, Experiment_Config, WAPE, RMSE)\n",
    "VALUES (\n",
    "  '{running_experiment.model}',               \n",
    "  '{FORECAST_TIMESTAMP}',\n",
    "  STRUCT(\n",
    "    '{running_experiment.name}' AS Name,\n",
    "    '{running_experiment.objective}' AS Objective,\n",
    "    {running_experiment.forecast_horizon} AS Forecast_Horizon,\n",
    "    {running_experiment.context_window} AS Context_Window,\n",
    "    '{running_experiment.data_granularity_unit}' AS Data_Granularity_Unit,\n",
    "    {json.dumps(running_experiment.holiday_regions)} AS Holiday_Regions,\n",
    "    {json.dumps(running_experiment.experiment_columns)} AS Experiment_Columns\n",
    "  ),\n",
    "  STRUCT(\n",
    "    {wape['overall']} AS Overall,\n",
    "    {wape['Tier 1']} AS Tier_1,\n",
    "    {wape['Tier 2']} AS Tier_2,\n",
    "    {wape['Tier 3']} AS Tier_3\n",
    "  ),\n",
    "  STRUCT(\n",
    "    {rmse['overall']} AS Overall,\n",
    "    {rmse['Tier 1']} AS Tier_1,\n",
    "    {rmse['Tier 2']} AS Tier_2,\n",
    "    {rmse['Tier 3']} AS Tier_3\n",
    "  )\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table.RowIterator at 0x7fffa430c5b0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query_and_wait(evaluation_insert_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
