{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb55dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/workspaces/b2b-wf-experiments/stacks/short_term_forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38104995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DatasetStatisticsConfig:\n",
    "    root_dir: Path\n",
    "    train_dataset: Path\n",
    "    test_dataset: Path\n",
    "    time_column: str\n",
    "    target_column: str\n",
    "    attribute_columns: List[str]\n",
    "    output_statistics: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ded841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ShortTermForecast.constants import *\n",
    "from src.ShortTermForecast.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9cc0796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH\n",
    "    ):\n",
    "        if config_filepath is not None:\n",
    "            self.config = read_yaml(config_filepath)\n",
    "            create_directories([self.config.artifacts_root])\n",
    "        \n",
    "        if params_filepath is not None:\n",
    "            self.params = read_yaml(params_filepath)\n",
    "\n",
    "    def get_dataset_statistics_dvc_config(self) -> DatasetStatisticsConfig:\n",
    "        general_configs = self.config.general_setup\n",
    "        cross_validation_config = self.config.cross_validation\n",
    "        dataset_statistics_config = self.config.dataset_statistics\n",
    "\n",
    "        create_directories([dataset_statistics_config.root_dir])\n",
    "\n",
    "        return DatasetStatisticsConfig(\n",
    "            root_dir=Path(dataset_statistics_config.root_dir),\n",
    "            train_dataset=Path(cross_validation_config.root_dir, cross_validation_config.train_file_name),\n",
    "            test_dataset=Path(cross_validation_config.root_dir, cross_validation_config.test_file_name),\n",
    "            time_column=general_configs.time_column,\n",
    "            target_column=general_configs.target_column,\n",
    "            attribute_columns=general_configs.attribute_columns,\n",
    "            output_statistics=Path(dataset_statistics_config.root_dir, dataset_statistics_config.output_file_name)\n",
    "        )\n",
    "\n",
    "    def get_dataset_statistics_kfp_config(\n",
    "        self,\n",
    "        train_dataset: str,\n",
    "        test_dataset: str,\n",
    "        time_column: str,\n",
    "        target_column: str,\n",
    "        attribute_columns: List[str],\n",
    "        output_statistics: str\n",
    "    ) -> DatasetStatisticsConfig:\n",
    "        return DatasetStatisticsConfig(\n",
    "            root_dir=None,\n",
    "            train_dataset=Path(train_dataset),\n",
    "            test_dataset=Path(test_dataset),\n",
    "            time_column=time_column,\n",
    "            target_column=target_column,\n",
    "            attribute_columns=attribute_columns,\n",
    "            output_statistics=Path(output_statistics)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9330a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import pandas as pd\n",
    "import json\n",
    "from src.ShortTermForecast import logger\n",
    "\n",
    "class DatasetStatistics:\n",
    "    def __init__(self, config: DatasetStatisticsConfig):\n",
    "        self.config = config\n",
    "        self.stats = None\n",
    "\n",
    "    def format_date(self, date):\n",
    "        \"\"\"Safely format a date, handling NaT values\"\"\"\n",
    "        return date.strftime(\"%Y-%m-%d\") if pd.notna(date) else None\n",
    "\n",
    "    def calculate_statistics(self, df: pd.DataFrame, dataset_type: str, split_number: int) -> Dict[str, any]:\n",
    "        df[self.config.time_column] = pd.to_datetime(df[self.config.time_column], errors='coerce')\n",
    "            \n",
    "        date_range_start = df[self.config.time_column].min()\n",
    "        date_range_end = df[self.config.time_column].max()\n",
    "        \n",
    "        stats = {\n",
    "            \"dataset_type\": dataset_type,\n",
    "            \"split_number\": split_number,\n",
    "            \"total_rows\": len(df),\n",
    "            \"date_range\": {\n",
    "                \"start\": self.format_date(date_range_start),\n",
    "                \"end\": self.format_date(date_range_end)\n",
    "            },\n",
    "            \"target_column\": {\n",
    "                \"mean\": float(df[self.config.target_column].mean()),\n",
    "                \"median\": float(df[self.config.target_column].median()),\n",
    "                \"min\": float(df[self.config.target_column].min()),\n",
    "                \"max\": float(df[self.config.target_column].max()),\n",
    "                \"std\": float(df[self.config.target_column].std()),\n",
    "                \"total\": float(df[self.config.target_column].sum())\n",
    "            },\n",
    "            \"null_counts\": df.isnull().sum().to_dict(),\n",
    "            \"categorical_columns\": {}\n",
    "        }\n",
    "\n",
    "        for col in self.config.attribute_columns:\n",
    "            value_counts = df[col].value_counts()\n",
    "            stats[\"categorical_columns\"][col] = {\n",
    "                \"unique_values\": int(df[col].nunique()),\n",
    "                \"top_5_values\": value_counts.nlargest(5).to_dict(),\n",
    "                \"null_count\": int(df[col].isnull().sum()),\n",
    "                \"total_count\": int(len(df)),\n",
    "                \"distribution_percentage\": value_counts.nlargest(5).apply(lambda x: float(x/len(df) * 100)).to_dict()\n",
    "            }\n",
    "\n",
    "        return stats\n",
    "\n",
    "    def generate_statistics(self) -> Dict[str, Dict[str, Dict[str, any]]]:\n",
    "        logger.info(\"Reading input datasets\")\n",
    "        try:\n",
    "            train_df = pd.read_csv(self.config.train_dataset)\n",
    "            test_df = pd.read_csv(self.config.test_dataset)\n",
    "            \n",
    "            train_df[self.config.time_column] = pd.to_datetime(train_df[self.config.time_column], errors='coerce')\n",
    "            test_df[self.config.time_column] = pd.to_datetime(test_df[self.config.time_column], errors='coerce')\n",
    "\n",
    "            all_statistics = {}\n",
    "\n",
    "            logger.info(\"Processing training splits\")\n",
    "            for split_index in range(1, 5):\n",
    "                split_train = train_df[train_df['split_index'] == split_index]\n",
    "                logger.info(f\"Processing training split {split_index} (shape: {split_train.shape})\")\n",
    "                all_statistics[f\"train_split_{split_index}\"] = self.calculate_statistics(split_train, \"train\", split_index)\n",
    "\n",
    "            logger.info(\"Processing test splits\")\n",
    "            for split_index in range(1, 5):\n",
    "                split_test = test_df[test_df['split_index'] == split_index]\n",
    "                logger.info(f\"Processing test split {split_index} (shape: {split_test.shape})\")\n",
    "                all_statistics[f\"test_split_{split_index}\"] = self.calculate_statistics(split_test, \"test\", split_index)\n",
    "                \n",
    "            logger.info(\"Calculating overall statistics\")\n",
    "            all_data = pd.concat([train_df, test_df])\n",
    "            all_statistics[\"overall\"] = self.calculate_statistics(all_data, \"overall\", 0)\n",
    "\n",
    "            earliest_date = all_data[self.config.time_column].min()\n",
    "            latest_date = all_data[self.config.time_column].max()\n",
    "            \n",
    "            all_statistics[\"summary\"] = {\n",
    "                \"total_rows\": {\n",
    "                    \"train\": len(train_df),\n",
    "                    \"test\": len(test_df),\n",
    "                    \"total\": len(all_data)\n",
    "                },\n",
    "                \"date_range\": {\n",
    "                    \"earliest\": self.format_date(earliest_date),\n",
    "                    \"latest\": self.format_date(latest_date)\n",
    "                },\n",
    "                \"splits_info\": {\n",
    "                    f\"split_{i}\": {\n",
    "                        \"train_rows\": len(train_df[train_df['split_index'] == i]),\n",
    "                        \"test_rows\": len(test_df[test_df['split_index'] == i])\n",
    "                    } for i in range(1, 5)\n",
    "                }\n",
    "            }\n",
    "\n",
    "            self.stats = all_statistics\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating statistics: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def save_statistics(self):\n",
    "        if self.stats is None:\n",
    "            logger.error(\"No statistics to save. Run generate_statistics() first.\")\n",
    "            return\n",
    "\n",
    "        logger.info(f\"Saving statistics to {self.config.output_statistics}\")\n",
    "        try:\n",
    "            with open(self.config.output_statistics, \"w\") as f:\n",
    "                json.dump(self.stats, f, indent=2)\n",
    "            logger.info(\"Statistics saved successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving statistics: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05cbba21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-15 20:28:31,551: INFO: 3603232476] >>>>>> stage Dataset Statistics Generation started <<<<<<\n",
      "[2025-04-15 20:28:31,557: INFO: common] yaml file: config/config.yaml loaded successfully\n",
      "[2025-04-15 20:28:31,560: INFO: common] Creating directory: artifacts\n",
      "[2025-04-15 20:28:31,562: INFO: common] yaml file: params.yaml loaded successfully\n",
      "[2025-04-15 20:28:31,564: INFO: common] Creating directory: artifacts/dataset_statistics\n",
      "[2025-04-15 20:28:31,565: INFO: 3781864347] Reading input datasets\n",
      "[2025-04-15 20:28:31,574: INFO: 3781864347] Processing training splits\n",
      "[2025-04-15 20:28:31,576: INFO: 3781864347] Processing training split 1 (shape: (0, 12))\n",
      "[2025-04-15 20:28:31,598: INFO: 3781864347] Processing training split 2 (shape: (0, 12))\n",
      "[2025-04-15 20:28:31,607: INFO: 3781864347] Processing training split 3 (shape: (0, 12))\n",
      "[2025-04-15 20:28:31,615: INFO: 3781864347] Processing training split 4 (shape: (0, 12))\n",
      "[2025-04-15 20:28:31,624: INFO: 3781864347] Processing test splits\n",
      "[2025-04-15 20:28:31,626: INFO: 3781864347] Processing test split 1 (shape: (0, 12))\n",
      "[2025-04-15 20:28:31,637: INFO: 3781864347] Processing test split 2 (shape: (0, 12))\n",
      "[2025-04-15 20:28:31,648: INFO: 3781864347] Processing test split 3 (shape: (0, 12))\n",
      "[2025-04-15 20:28:31,658: INFO: 3781864347] Processing test split 4 (shape: (0, 12))\n",
      "[2025-04-15 20:28:31,666: INFO: 3781864347] Calculating overall statistics\n",
      "[2025-04-15 20:28:31,679: INFO: 3781864347] Saving statistics to artifacts/dataset_statistics/data_stats.json\n",
      "[2025-04-15 20:28:31,684: INFO: 3781864347] Statistics saved successfully\n",
      "[2025-04-15 20:28:31,685: INFO: 3603232476] >>>>>> stage Dataset Statistics Generation completed <<<<<<\n",
      "[2025-04-15 20:28:31,686: INFO: 3603232476] \n",
      "x==================================================x\n"
     ]
    }
   ],
   "source": [
    "from src.ShortTermForecast import logger\n",
    "\n",
    "STAGE_NAME = \"Dataset Statistics Generation\"\n",
    "\n",
    "class DatasetStatisticsPipeline:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def main(self):\n",
    "        config = ConfigurationManager()\n",
    "        dataset_statistics = DatasetStatistics(config.get_dataset_statistics_dvc_config())\n",
    "        dataset_statistics.generate_statistics()\n",
    "        dataset_statistics.save_statistics()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        logger.info(f\">>>>>> stage {STAGE_NAME} started <<<<<<\")\n",
    "        obj = DatasetStatisticsPipeline()\n",
    "        obj.main()\n",
    "        logger.info(f\">>>>>> stage {STAGE_NAME} completed <<<<<<\")\n",
    "        logger.info(\"\\nx\" + \"=\" * 50 + \"x\")\n",
    "    except Exception as e:\n",
    "        logger.exception(e)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96600f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
